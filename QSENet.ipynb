{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    NLLLoss,\n",
    "    MaxPool2d,\n",
    "    Flatten,\n",
    "    Sequential,\n",
    "    ReLU,\n",
    ")\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS\n",
    "import torch.nn as nn\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap , EfficientSU2\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if torch.cuda.is_available() and use_cuda:  \n",
    "    device = 'cuda:0'\n",
    "print(f'Using {device} for training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　Hyperparameter\n",
    "batch_size = 64\n",
    "\n",
    "# data\n",
    "test_input = torch.randn((1,3,32,32)).to(device)\n",
    "class_n = 2\n",
    "train_samples = -1\n",
    "test_samples = -1\n",
    "\n",
    "# model config\n",
    "qubitn = 3\n",
    "q_depth = 1\n",
    "out_type = 'pool'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "manual_seed(42)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "def get_class_indices(dataset, classes):\n",
    "    indices = []\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset.targets[i] in classes:\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "\n",
    "classes_of_interest = [3, 88]\n",
    "train_indices = get_class_indices(trainset, classes_of_interest)\n",
    "\n",
    "\n",
    "X_train = Subset(trainset, train_indices)\n",
    "\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "\n",
    "train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_relabel(dataset, classes):\n",
    "    indices = []\n",
    "    new_labels = []\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset.targets[i] == classes[0]:\n",
    "            indices.append(i)\n",
    "            new_labels.append(0)  # Remap class 3 to 0\n",
    "        elif dataset.targets[i] == classes[1]:\n",
    "            indices.append(i)\n",
    "            new_labels.append(1)  # Remap class 88 to 1\n",
    "    return indices, new_labels\n",
    "\n",
    "\n",
    "train_indices, train_new_labels = filter_and_relabel(trainset, classes_of_interest)\n",
    "\n",
    "\n",
    "train_subset = Subset(trainset, train_indices)\n",
    "for i, idx in enumerate(train_indices):\n",
    "    train_subset.dataset.targets[idx] = train_new_labels[i]\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_relabel(dataset, classes):\n",
    "    indices = []\n",
    "    new_labels = []\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset.targets[i] == classes[0]:\n",
    "            indices.append(i)\n",
    "            new_labels.append(0)  # Remap class 3 to 0\n",
    "        elif dataset.targets[i] == classes[1]:\n",
    "            indices.append(i)\n",
    "            new_labels.append(1)  # Remap class 88 to 1\n",
    "    return indices, new_labels\n",
    "\n",
    "\n",
    "manual_seed(5)\n",
    "\n",
    "\n",
    "testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "test_indices, test_new_labels = filter_and_relabel(testset, classes_of_interest)\n",
    "\n",
    "\n",
    "test_samples = 50  \n",
    "test_indices = test_indices[:test_samples]\n",
    "test_new_labels = test_new_labels[:test_samples]\n",
    "\n",
    "\n",
    "test_subset = Subset(testset, test_indices)\n",
    "for i, idx in enumerate(test_indices):\n",
    "    test_subset.dataset.targets[idx] = test_new_labels[i]\n",
    "\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNet(Module):\n",
    "    def __init__(self,class_n):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(1, 9, kernel_size=5)\n",
    "        self.conv2 = Conv2d(9, 16, kernel_size=5)\n",
    "        self.dropout = Dropout2d()\n",
    "        self.fc1 = Linear(256, 64)\n",
    "        self.fc2 = Linear(64, class_n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SU2 = [\n",
    "    qml.PauliX ,\n",
    "    qml.PauliY ,\n",
    "    qml.PauliZ \n",
    "]\n",
    "R = [\n",
    "    qml.RX ,\n",
    "    qml.RY ,\n",
    "    qml.RZ\n",
    "]\n",
    "def XYZ(x , qid) :\n",
    "    for r , _x in zip(R,x) :\n",
    "        r(_x, wires = qid)\n",
    "\n",
    "def entangle_layer(targets) :\n",
    "    for tg in targets :\n",
    "        qml.CNOT(wires = tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('lightning.qubit', wires=qubitn)\n",
    "#dev = qml.device('default.qubit', wires=qubitn)\n",
    "\n",
    "@qml.qnode(dev , interface = 'torch')\n",
    "def circuit(inputs , weight) :\n",
    "    #　x with shape (qubit , encode input)\n",
    "    #  weights with shape (depth, qubit , weights,2)\n",
    "    for idx ,_x in enumerate(inputs.view(3,3)) :\n",
    "        XYZ(_x , idx)\n",
    "\n",
    "    #  entangle structure = {i , i+1}\n",
    "    entangle = [[i ,i+1] for i in range(qubitn-1)]\n",
    "    for idd , single_layer in enumerate(weight) :\n",
    "        for qid , weights in enumerate(single_layer) :\n",
    "            XYZ(weights[0] ,qid)\n",
    "        entangle_layer(entangle)\n",
    "        for qid , weights in enumerate(single_layer) :\n",
    "            XYZ(weights[1] ,qid)\n",
    "    rs = []\n",
    "    if out_type == \"pool\" :\n",
    "        for pauli in SU2 :\n",
    "            ob = pauli(0)\n",
    "            for i in range(1 ,qubitn) :\n",
    "                ob = ob @ pauli(i)\n",
    "            rs.append(qml.expval(ob))\n",
    "    else :\n",
    "        for i in range(qubitn) :\n",
    "            rs.append(qml.expval(qml.PauliZ(i)))\n",
    "    return  rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNN(nn.Module) :\n",
    "    def __init__(self , qubitn , q_depth , out) -> None:\n",
    "        super(QNN , self).__init__()\n",
    "        #self.weights = nn.Parameter(torch.randn((q_depth ,qubitn , 2,3)))\n",
    "        self.qnn =  qml.qnn.TorchLayer(circuit , {\"weight\" : ( q_depth,qubitn , 2,3)})\n",
    "        self.out = out\n",
    "        self.qubitn = qubitn\n",
    "        self.q_depth  = q_depth\n",
    "\n",
    "    def forward(self, input):\n",
    "        b,c  = input.shape\n",
    "\n",
    "        # Batched forward\n",
    "        out = self.qnn(input[0])\n",
    "        for idx , i in  enumerate(input[1:] ):\n",
    "            out = torch.cat((out , self.qnn(input[idx])))\n",
    "        return torch.reshape(out , (b,3))\n",
    "\n",
    "class QSELayer(nn.Module):\n",
    "    def __init__(self,channel, qubitn , q_depth , out):\n",
    "        super(QSELayer,self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        fin = qubitn\n",
    "        if out == 'pool' :\n",
    "            fin = 3\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(fin ,channel),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.qnn = QNN(qubitn=qubitn , q_depth= q_depth , out = out)\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.qnn(y)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Hybrid Net with Quantum Pooling\n",
    "class QSENet(Module):\n",
    "    def __init__(self, qubitn, class_n, q_depth, out):\n",
    "        super().__init__()\n",
    "        chn = qubitn * 3\n",
    "        self.conv1 = Conv2d(3, chn, kernel_size=5)  # Modified to accept 3-channel input\n",
    "        self.qse = QSELayer(qubitn=qubitn, channel=chn, q_depth=q_depth, out=out)\n",
    "        self.conv2 = Conv2d(chn, 16, kernel_size=5)\n",
    "        self.dropout = Dropout2d()\n",
    "        self.fc1 = Linear(400, 64)\n",
    "        self.fc2 = Linear(64, class_n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.qse(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "QPSE = QSENet(qubitn = qubitn ,class_n = class_n ,q_depth=q_depth, out=out_type)\n",
    "QPSE.to(device)\n",
    "QPSE(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QPSE\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, optimizer, and loss function\n",
    "\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = CrossEntropyLoss()\n",
    "\n",
    "# Start training\n",
    "epochs = 20  # Set number of epochs\n",
    "loss_list = []  # Store loss history\n",
    "model.train()  # Set model to training mode\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad(set_to_none=True)  # Initialize gradient\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)  # Forward pass\n",
    "        loss = loss_func(output, target)  # Calculate loss\n",
    "        #print(batch_idx)\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize weights\n",
    "        total_loss.append(loss.item())  # Store loss\n",
    "        print(\"\\rDone {:.3f} %\" .format(100*batch_idx/len(train_loader)), end='')\n",
    "    loss_list.append(sum(total_loss) / len(total_loss))\n",
    "    print(\"\\nTraining [{:.0f}%]\\tLoss: {:.4f}\".format(100.0 * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss convergence\n",
    "plt.plot(loss_list)\n",
    "plt.title(\"Hybrid NN Training Convergence\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Neg. Log Likelihood Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = \"Qmodel4.pt\"\n",
    "torch.save(model.state_dict(), save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_name = \"Qmodel4.pt\"\n",
    "modelt = model\n",
    "modelt.load_state_dict(torch.load(save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelt.eval()  # set model to evaluation mode\n",
    "target_loader = test_loader\n",
    "modelt.to(device)\n",
    "with no_grad():\n",
    "\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(target_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = modelt(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(target_loader) / batch_size * 100\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
