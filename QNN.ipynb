{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 5                \n",
    "step = 0.001              \n",
    "batch_size = 32             \n",
    "num_epochs = 50          \n",
    "q_depth = 10                \n",
    "gamma_lr_scheduler = 0.1    \n",
    "q_delta = 0.01             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  \n",
    "])\n",
    "\n",
    "\n",
    "data_dir = './cifar100_data'\n",
    "\n",
    "\n",
    "trainset = datasets.CIFAR100(root=data_dir, train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "testset = datasets.CIFAR100(root=data_dir, train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': trainloader,\n",
    "    'test': testloader\n",
    "}\n",
    "\n",
    "\n",
    "class_names = trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "def get_class_indices(dataset, classes):\n",
    "    # 获取特定类别的索引\n",
    "    indices = []\n",
    "    for i in range(len(dataset)):\n",
    "        # 检查数据集中样本的类别\n",
    "        if dataset.targets[i] in classes:\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "# 您感兴趣的类别（第 3 和第 88 类）\n",
    "classes_of_interest = [3, 88]  # 类别索引从 0 开始，因此减去 1\n",
    "\n",
    "# 为训练集和测试集创建子集\n",
    "train_indices = get_class_indices(trainset, classes_of_interest)\n",
    "test_indices = get_class_indices(testset, classes_of_interest)\n",
    "\n",
    "train_subset = Subset(trainset, train_indices)\n",
    "test_subset = Subset(testset, test_indices)\n",
    "\n",
    "# 创建数据加载器\n",
    "trainloader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': trainloader,\n",
    "    'test': testloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_layer(nqubits):\n",
    "   \n",
    "    for idx in range(nqubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "\n",
    "\n",
    "def RY_layer(w):\n",
    "   \n",
    "    for idx, element in enumerate(w):\n",
    "        qml.RY(element, wires=idx)\n",
    "\n",
    "\n",
    "def entangling_layer(nqubits):\n",
    "   \n",
    "    # In other words it should apply something like :\n",
    "    # CNOT  CNOT  CNOT  CNOT...  CNOT\n",
    "    #   CNOT  CNOT  CNOT...  CNOT\n",
    "    for i in range(0, nqubits - 1, 2):  # Loop over even indices: i=0,2,...N-2\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    for i in range(1, nqubits - 1, 2):  # Loop over odd indices:  i=1,3,...N-3\n",
    "        qml.CNOT(wires=[i, i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_net(q_input_features, q_weights_flat):\n",
    "    \"\"\"\n",
    "    The variational quantum circuit.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
    "\n",
    "\n",
    "    H_layer(n_qubits)\n",
    "\n",
    "    RY_layer(q_input_features)\n",
    "\n",
    "\n",
    "    for k in range(q_depth):\n",
    "        entangling_layer(n_qubits)\n",
    "        RY_layer(q_weights[k])\n",
    "    \n",
    "\n",
    "  \n",
    "    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(n_qubits)]\n",
    "    return tuple(exp_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_circuit():\n",
    "    H_layer(n_qubits)\n",
    "    RY_layer(np.random.random(n_qubits))\n",
    "    entangling_layer(n_qubits)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "drawn_circuit = qml.draw(quantum_circuit)\n",
    "\n",
    "\n",
    "print(drawn_circuit())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DressedQuantumNet(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "    \n",
    "\n",
    "        super().__init__()\n",
    "        self.pre_net = nn.Linear(100, n_qubits)\n",
    "        self.q_params = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits))\n",
    "        self.post_net = nn.Linear(n_qubits, 100)\n",
    "\n",
    "    def forward(self, input_features):\n",
    "\n",
    "        \n",
    "        pre_out = self.pre_net(input_features)\n",
    "        q_in = torch.tanh(pre_out) * np.pi / 2.0\n",
    "\n",
    "        \n",
    "        q_out = torch.Tensor(0, n_qubits).to(device)  \n",
    "        for elem in q_in:\n",
    "            q_out_elem_vals = quantum_net(elem.to(device), self.q_params.to(device)) \n",
    "            q_out_elem = torch.tensor(q_out_elem_vals).float().unsqueeze(0).to(device)\n",
    "            q_out = torch.cat((q_out, q_out_elem))\n",
    "\n",
    "        return self.post_net(q_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self,channel, reduction):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class QCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(6,9, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(9, 16, kernel_size=3)\n",
    "        self.btch = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(3, 6, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(16, 16, kernel_size=3)\n",
    "        #self.conv5 = nn.Conv2d(16, 16, kernel_size=3)\n",
    "        self.se1 = SELayer(9 ,4)\n",
    "        self.se2 = SELayer(16 ,4)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(1600, 256)\n",
    "        self.fc2 = nn.Linear(256, 100)\n",
    "        self.quantum_layer = DressedQuantumNet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = self.se1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #x = self.btch(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        #x = F.relu(self.conv5(x))\n",
    "        #x = self.se2(x)\n",
    "        #x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.quantum_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QCNet()\n",
    "#model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=step) \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "def train_model(model, trainloader, criterion, optimizer, num_epochs, device):\n",
    "    best_acc = 0.0  \n",
    "    best_loss = float('inf') \n",
    "\n",
    "    for epoch in range(num_epochs): \n",
    "        start_time = time.time()  \n",
    "\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % 100 == 99:    \n",
    "                current_loss = running_loss / 100\n",
    "                current_accuracy = 100 * correct / total\n",
    "                print(f'[Epoch: {epoch + 1}, Batch: {i + 1}] Loss: {current_loss:.3f}, Accuracy: {current_accuracy:.2f}%')\n",
    "                running_loss = 0.0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "\n",
    "        \n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "\n",
    "        \n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "\n",
    "        end_time = time.time()  \n",
    "        epoch_duration = end_time - start_time  \n",
    "        print(f'Epoch {epoch + 1} completed in {epoch_duration:.2f} seconds')\n",
    "\n",
    "    print(f'Finished Training. Best Accuracy: {best_acc:.2f}%, Best Loss: {best_loss:.3f}')\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "def test_model(model, trainloader, criterion, optimizer, num_epochs, device):\n",
    "    best_acc = 0.0  \n",
    "    best_loss = float('inf')  \n",
    "\n",
    "    for epoch in range(num_epochs):  \n",
    "        start_time = time.time()  \n",
    "\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % 100 == 99:   \n",
    "                current_loss = running_loss / 100\n",
    "                current_accuracy = 100 * correct / total\n",
    "                print(f'[Epoch: {epoch + 1}, Batch: {i + 1}] Loss: {current_loss:.3f}, Accuracy: {current_accuracy:.2f}%')\n",
    "                running_loss = 0.0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "\n",
    "        \n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "\n",
    "        \n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "\n",
    "        end_time = time.time()  \n",
    "        epoch_duration = end_time - start_time \n",
    "        print(f'Epoch {epoch + 1} completed in {epoch_duration:.2f} seconds')\n",
    "\n",
    "    print(f'Finished Training. Best Accuracy: {best_acc:.2f}%, Best Loss: {best_loss:.3f}')\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, trainloader, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, testloader, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  \n",
    "\n",
    "def visualize_model(model, num_images=6, fig_name=\"Predictions\"):\n",
    "    images_so_far = 0\n",
    "    plt.figure(fig_name)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'Predicted: {class_names[preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model, num_images=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model.eval() \n",
    "\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
